# AI for Science (AI4S) â€” Reading List & Survey Outline

**Last updated:** **12 Aug 2025**

> Curated resources and a living outline for an upcoming **Survey** on the landscape of *Artificial Intelligence for Science* â€” with special focus on **LLM foundation models** (textâ€‘centric) and **Scientist Agents** for literature, planning, coding, and realâ€‘world labs.

---

## Table of Contents

1. [Survey Outline](#survey-outline)
2. [Related Work â€“ History & Foundational Surveys](#related-work--history--foundational-surveys)
3. [LLM & Foundation Models for Science](#llm--foundation-models-for-science)
   - [Generic (Textâ€‘centric) LLMs](#generic-textcentric-llms)
   - [Domainâ€‘Specific Sciâ€‘LLMs](#domain-specific-sci-llms)
   - [Scientistâ€‘Agent Systems](#scientist-agent-systems)
   - [Real Experimental Setups (Autonomous Labs)](#real-experimental-setups-autonomous-labs)
   - [Evaluation & Benchmarks for Science Agents](#evaluation--benchmarks-for-science-agents)
   - [Tooling / Stacks for Agentic Workflows](#tooling--stacks-for-agentic-workflows)
   - [Reproducibility & Governance](#reproducibility--governance)
4. [Domain Breakthroughs](#domain-breakthroughs)
5. [Datasets & Benchmarks](#datasets--benchmarks)
6. [Software & Frameworks](#software--frameworks)
7. [Conferences & Community](#conferences--community)
8. [Staying Current](#staying-current)
9. [ğŸ“† Progress Timeline](#-progress-timeline)
10. [ğŸ“… Highâ€‘Level Milestone Plan](#-high-level-milestone-plan)
11. [Contributing](#contributing)
12. [License](#license)

---

## Survey Outline

### Artificial Intelligence for Scientific Discovery: A Comprehensive Survey

Artificial intelligence (AI) is reshaping scientific practice â€” from hypothesis generation to autonomous experimentation. This survey synthesizes methods and systems across **deep learning**, **reinforcement learning**, **generative models**, **neuroâ€‘symbolic AI**, **physicsâ€‘informed learning**, **geometric/equivariant DL**, **graph neural networks**, **neural operators**, and **large foundation models (LLMs)**. We map progress in **materials**, **chemistry/biomedicine**, **climate & earth**, and **fundamental physics**, and examine challenges (data sparsity, evaluation, reproducibility, safety). We close with trajectories in **autonomous labs**, **agentic systems**, **foundation models**, and **AIâ€‘assisted theory building**.

#### 1. Introduction
- **1.1** What is â€œAI for Scienceâ€? Scope and principles
- **1.2** Historical evolution of AI in scientific research
- **1.3** Motivation and contributions of this survey

**1.1.1 Generic AI for Science**
- Physicsâ€‘informed & knowledgeâ€‘guided learning
- Geometric & equivariant deep learning
- Neural operators & surrogates
- Foundation models & LLM agents for science
- Automated experiment design & lab robotics
- Benchmarks, evaluation, trust, and interpretability

**1.1.2 Domainâ€‘Specific AI for Science**
- Life sciences & structural biology
- Chemistry & materials discovery
- Earth, climate & environmental science
- Physics, astronomy & cosmology
- Energy, engineering & manufacturing
- Medicine & healthcare imaging/VQA

#### 2. Core AI Methodologies for Science
- **2.1** Deep learning architectures  
- **2.2** Reinforcement learning  
- **2.3** Generative models (design, simulation, data augmentation)  
- **2.4** Symbolic & neuroâ€‘symbolic approaches  
- **2.5** Physicsâ€‘Informed Neural Networks (PINNs)  
- **2.6** Graph Neural Networks (GNNs)  

#### 3. Application Domains & Breakthroughs
- **3.1** Materials discovery  
- **3.2** Drug design & biomedicine  
- **3.3** Climate & environmental science  
- **3.4** Fundamental physics & HEP  

#### 4. Challenges & Limitations
- **4.1** Data scarcity/quality & domain shifts  
- **4.2** Interpretability, verification, & mechanistic insight  
- **4.3** Reproducibility & provenance in AIâ€‘driven experiments  
- **4.4** Ethical, legal, biosafety/chemâ€‘safety considerations  

#### 5. Emerging Trends
- **5.1** Interdisciplinary AI & theoryâ€‘guided ML  
- **5.2** Autonomous scientific discovery systems (closedâ€‘loop labs)  
- **5.3** Foundation models for science (text, code, structure, multiâ€‘modal)  
- **5.4** Quantum + AI & HPCâ€‘scale FM training  

---

## Related Work â€“ History & Foundational Surveys

### A. Historical Milestones

| Year | Milestone | Why it matters |
| ---- | --------- | -------------- |
| 2016 | **AlphaGo** (Nature) | First splashy combo of deep nets + RL that inspired algorithmic exploration across science. |
| 2021 | **AlphaFoldÂ 2** | Protein structure prediction jumps to nearâ€‘experimental accuracy; catalyzes modern AI4S. |
| 2023 | **GNoME** predicts **2.2M** stable crystals | Ordersâ€‘ofâ€‘magnitude acceleration in materials candidate generation. |
| 2024 | **Sakana AI â€“ The AI Scientist** | â€œIdeaâ†’codeâ†’runâ†’analyzeâ†’draftâ†’autoâ€‘reviewâ€ endâ€‘toâ€‘end pipeline. |
| 2024 | **AlphaFoldÂ 3** | Extends to complexes (proteins, nucleic acids, ligands) with diffusionâ€‘style architecture. |
| 2025 | **AIâ€‘driven autonomous lab (Polybot) @ Argonne/UChicago** | LLM/agent loops integrated with real experimentation. |
| 2025 | **AI Coâ€‘Scientist (Google)** | Gemini 2.0â€‘powered multiâ€‘agent system for hypothesisâ†’planâ†’experiment. |
| 2025 | **ASIâ€‘Arch (â€œAlphaGo momentâ€ for modelâ€‘architecture discovery)** | Autonomous endâ€‘toâ€‘end research in model architecture space. |

> âš ï¸ *Caveat:* Some claims around â€œautonomyâ€ vs. â€œaugmentationâ€ are evolving; many systems remain humanâ€‘inâ€‘theâ€‘loop.

### B. Foundational Surveys & Whiteâ€‘Papers

- **AI for Science 2025** (Nature feature) â€“ landscape + policy angles.  
- **A New Golden Age of Discovery** (DeepMind, 2024) â€“ opportunity pillars for FMâ€‘driven science.  
- **AI for Science: An Emerging Agenda** (Berens *etâ€¯al.* 2023) â€“ taxonomy & open questions.  
- **PINNs & Extensions** (Raissi *etâ€¯al.* 2024); **From PINNs to PIKANs** (2024).  
- **Geometric Deep Learning â€“ Blueprint** (Bronstein *etâ€¯al.* 2021).  
- **NASA/AGU Foundation Models for Science** (Ramachandran 2023â€“2024).  

<details>
<summary>ğŸ” Key Concepts & Principles (concise)</summary>

- **AI vs. AI4S** â€” AI4S applies ML/DL/statistics/control to *scientific* problems, emphasizing hypothesisâ€‘driven workflows and experimental protocols.  
- **Augmentation â†’ Autonomy** â€” Todayâ€™s systems mainly **augment** human scientists; autonomy emerges in narrow loops.  
- **Hybridization** â€” Physicsâ€‘informed, neuroâ€‘symbolic, and graphâ€‘based methods blend data + priors for extrapolation and trust.  
</details>

---

## LLM & Foundation Models for Science

### Generic (Textâ€‘centric) LLMs

Use frontier or openâ€‘weight LLMs for: literature QA, research planning, code gen for simulations, lab notebook analysis, experimental design checklists, and scientific writing. Track:

**Mini â€œModel Cardâ€ fields to capture (per model):** *context length; toolâ€‘use/calling; functionâ€‘calling/sandboxed code; multimodality; license & usage restrictions; safety guardrails; typical strengths/limits on science tasks; eval results on science benchmarks; fineâ€‘tuning/LoRA options; hardware footprint; cost/latency.*

### Domainâ€‘Specific Sciâ€‘LLMs

Bio/med: **BioMedLM**; **BioGPT**  
Scienceâ€‘general: **SciGLM** (+ SciInstruct)  
Materials/Chemistry: emerging Mat/Chemâ€‘tuned LLMs (e.g., SciDFM, ChemDFM perspectives & workshop papers)

> See links in Reading List below; include *limitations* (hallucinations, citation errors, unit handling) and *mitigations* (RAG w/ provenance, toolâ€‘use, explicit calculators, structure parsers, simulation callâ€‘outs).

### Scientistâ€‘Agent Systems

**Literatureâ€‘first agents:**  
- **PaperQA2** (highâ€‘accuracy paper RAG, supports LitQA2)  

**Domain agents (examples):**  
- **ChemCrow** (LLM + dozens of chemistry tools)  
- **SynAsk** (organic synthesis QA platform)

**Endâ€‘toâ€‘end research agents:**  
- **AI Coâ€‘Scientist** (Geminiâ€‘2.0 multiâ€‘agent; hypothesisâ†’planâ†’iterate)  
- **The AI Scientist** (Sakana; ideaâ†’codeâ†’runâ†’analyzeâ†’draftâ†’autoâ€‘review)  
- **ASIâ€‘Arch** (autonomous architecture discovery)

### Real Experimental Setups (Autonomous Labs)

- **ChemOS / ChemOSÂ 2.0** (orchestration for selfâ€‘driving labs)  
- **Mobile robotic chemist** (autonomous photocatalysis campaign)  
- **Polybot (Argonne/UChicago)** â€” AIâ€‘driven autonomous materials lab  
- Reviews & community efforts on SDLs, SiLA2 instrument control, and lab safety SOPs.

### Evaluation & Benchmarks for Science Agents

**Reasoning / problemâ€‘solving:** SciBench (physics/chem/math)  
**Literature research:** LitQA2 (retrieval, grounded summaries, contradiction checks)  
**Multiâ€‘turn agency:** AgentBoard (longâ€‘horizon multiâ€‘step tasks)  
**Safety:** ChemSafetyBench (+ biosecurity eval notes)

**Report (per agent):** task success; groundedness & citation quality; reproducibility (seeds/envs); latency/cost; toolâ€‘use coverage; safety flags.

### Tooling / Stacks for Agentic Workflows

- **Orchestration:** LangGraph; AutoGen; Semantic Kernel; CrewAI  
- **Evidence & scholarly graphs:** OpenAlex; ORKG; structured RAG stacks  
- **Execution & numerics:** unitâ€‘aware calculators; sandboxes; JAX/NumPy/PyTorch hooks  
- **MLOps for agents:** tracing (LangSmithâ€‘style), dataset curation, prompt/version control, eval harnesses

### Reproducibility & Governance

- Dataset/model cards; data licenses; *seeds + exact env capture* (containers/hashes); experiment logs & provenance (papers, code, data, config, tools used)  
- Humanâ€‘inâ€‘theâ€‘loop checkpoints for risky actions (chem/bio); redâ€‘teaming & domainâ€‘expert review; safety guidelines (export controls, dualâ€‘use awareness)

---

## Reading List

### 1) Roadâ€‘maps & Bigâ€‘Picture Overviews

| Year | Reference | Why it matters |
| ---- | --------- | -------------- |
| 2025 | **â€œAI for Science 2025â€** (*Nature* feature) | Landscape snapshot & policy challenges. |
| 2024 | **â€œA New Golden Age of Discoveryâ€** (DeepMind white paper) | Opportunity pillars for FMâ€‘driven science. |
| 2024 | **PINNs & Extensions** (RaissiÂ *etâ€¯al.*) | Comprehensive survey of physicsâ€‘informed learning. |
| 2024 | **FromÂ PINNsÂ toÂ PIKANs** (ToscanoÂ *etâ€¯al.*) | New directions for physicsâ€‘guided ML. |
| 2023 | **â€œAI for Science: An Emerging Agendaâ€** (BerensÂ *etâ€¯al.*) | Taxonomy & open questions. |
| 2020 | **â€œThe Automation of Scienceâ€** (KingÂ *etâ€¯al.*, *Science*) | Classic manifesto for autonomous labs. |

### 2) Core Methodologies

#### 2.1 Physicsâ€‘Informed & Knowledgeâ€‘Guided Learning
- RaissiÂ *etâ€¯al.*Â 2019 â€” Seminal PINNs  
- RaissiÂ *etâ€¯al.*Â 2024 â€” PINNs & extensions survey  
- ZhaoÂ *etâ€¯al.*Â 2024 â€” PINNs for fluid dynamics  
- ToscanoÂ *etâ€¯al.*Â 2024 â€” From PINNs to PIKANs

#### 2.2 GNNs for Molecules & Materials
- **GNoME** â€” Graph networks for largeâ€‘scale materials discovery  
- Defect diffusion GNN (ChemRxivÂ 2024)  
- Derivativeâ€‘based GNN preâ€‘training (RSC Digital DiscoveryÂ 2024)

#### 2.3 Geometric & Equivariant Deep Learning
- BronsteinÂ *etâ€¯al.*Â 2021 â€” Geometric DL blueprint  
- EGraFFBenchÂ 2023 â€” Evaluation of E(3)â€‘equivariant GNNs

#### 2.4 Neural Operators & Surrogate Physics
- **FourCastNet** (2022) â€” learned surrogates for atmospheric dynamics  
- **WeatherNext** (DeepMindÂ 2025) â€” SOTA weather forecasting family

#### 2.5 Foundation Models & LLM Agents for Science (selected)
- **Transforming Science with LLMs** (EgerÂ *etâ€¯al.*Â 2025) â€“ survey of tools across the research cycle  
- **Foundation models for materials discovery** (Pyzerâ€‘KnappÂ *etâ€¯al.*Â 2025) â€“ perspective on FM classes & future directions  
- **SciGLM & SciInstruct** (2024â€“2025) â€“ scientific instructionâ€‘tuning for collegeâ€‘level reasoning  
- **BioMedLM** (Stanford CRFM) & **BioGPT** (Microsoft) â€“ biomedical Sciâ€‘LLMs  
- **AI Coâ€‘Scientist** (Google,Â 2025) â€“ multiâ€‘agent hypothesisâ†’planâ†’experiment system  
- **The AI Scientist** (Sakana,Â 2024) â€“ fully automated discovery pipeline  
- **ASIâ€‘Arch** (2025) â€“ autonomous modelâ€‘architecture discovery

### Scientistâ€‘Agent Systems (LLMâ€‘centric)

**A. Generic vs. Domainâ€‘Specific LLMs**  
- **Generic LLMs (textâ€‘centric):** frontier/openâ€‘weight models via API or local hosting for literature QA, planning, coding simulations, and lab data triage.  
- **Domainâ€‘Specific Sciâ€‘LLMs:** biomedical (BioMedLM/BioGPT), scienceâ€‘general (SciGLM/SciInstruct), materials/chemistry (emerging Chem/Mat FM/LLMs).

> **For each model, track:** context length â–ª toolâ€‘use â–ª multimodality â–ª license â–ª strengths/limits â–ª benchmark results â–ª fineâ€‘tuning paths â–ª cost/latency.

**B. Scientistâ€‘Agent Papers & Code (examples)**  
- **PaperQA2**; **LitQA2** benchmark alignment  
- **ChemCrow**; **SynAsk**  
- **AI Coâ€‘Scientist**; **AI Scientist**; **ASIâ€‘Arch**

**C. Real Experimental Setups (Autonomous Labs)**  
- **ChemOS / ChemOSÂ 2.0** (orchestration)  
- **Mobile robotic chemist** (NatureÂ 2020)  
- **Argonne/UChicago Polybot** (autonomous materials discovery)

**D. Evaluation & Benchmarks for Science Agents**  
- **SciBench** â–ª **LitQA2** â–ª **AgentBoard** â–ª **ChemSafetyBench** (+ biosecurity note)  
- **Report metrics:** groundedness/citation quality â–ª reproducibility (seed/env) â–ª success rate â–ª latency & cost â–ª safety flags

**E. Tooling / Stacks**  
- **Orchestration:** LangGraph â–ª AutoGen â–ª Semantic Kernel â–ª CrewAI  
- **Evidence & data:** OpenAlex â–ª ORKG â–ª RAG stacks â–ª calculators/sandboxes  
- **AgentOps:** tracing/evals â–ª prompt/versioning â–ª dataset curation

**F. Reproducibility & Governance**  
- Dataset/model cards â–ª environment capture â–ª labâ€‘safety SOPs â–ª redâ€‘teaming checklists

---

## Domain Breakthroughs

| Area | Key Papers / Systems | Highlight |
| --- | --- | --- |
| Structural Biology | **AlphaFoldÂ 3** (2024) | Joint complex prediction (proteins, nucleic acids, ligands) with diffusionâ€‘style architecture. |
| Materials Science | **GNoME** (2023) | **2.2M** stable crystals predicted; many now synthesized via Aâ€‘Lab/partners. |
| Autonomous Labs | StachÂ *etâ€¯al.*Â (2023) | Closedâ€‘loop frameworks for robotic discovery. |
| Semiconductor Design | Google RL floorâ€‘planning (2021) | RL cuts layout time from weeks to hours. |
| Catalysis | **OCx24** dataset (2024) | Bridges experiment+computation for COâ‚‚RR/HER at industrially relevant conditions. |
| Climate & Weather | FourCastNet; **WeatherNext** | Neural surrogates rival/beat traditional NWP on select regimes. |
| Fundamental Physics | GraphNet tracking at LHC (2021) | Realâ€‘time particle track finding with GNNs. |
| Astronomy & Cosmology | SimBIG (2023); CosmoGAN (2017) | Simulationâ€‘based inference & generative LSS. |
| AI Research | **ASIâ€‘Arch** (2025) | Autonomous architecture discovery (multiâ€‘agent). |

---

## Datasets & Benchmarks

- **Materials & Chemistry:** Materials Project â–ª OQMD â–ª OC20 â–ª **OC22** â–ª **OCx24 (2024)**  
- **Biology:** PDB â–ª UniRefÂ 50 â–ª AlphaFoldÂ DB â–ª RNAcentral  
- **Climate:** ERA5 Reanalysis â–ª ClimateBench  
- **Visionâ€‘Language (medical/science):** VQAâ€‘RAD (2018) â–ª PathVQA (2020) â–ª PMCâ€‘VQA (2023) â–ª ScienceQA (2023) â–ª ChartQA (2022) â–ª MIMICâ€‘CXR (2019) â–ª IUÂ Xâ€‘Ray (2015)  
- **Crossâ€‘discipline leaderboards:** ScienceBench â–ª Holobot Challenge

---

## Software & Frameworks

| Tool | Link |
| ---- | ---- |
| **LangGraph** (agent graphs) | https://www.langchain.com/langgraph |
| **AutoGen** (multiâ€‘agent conv.) | https://microsoft.github.io/autogen/ |
| **Semantic Kernel** (agent SDK) | https://github.com/microsoft/semantic-kernel |
| **CrewAI** (lean agent framework) | https://github.com/crewAIInc/crewAI |
| **PaperQA2** (paperâ€‘centric RAG) | https://github.com/Future-House/paper-qa |
| **DeepXDE** | https://github.com/lululxvi/deepxde |
| **SciANN** | https://github.com/sciann/sciann |
| **NVIDIA Modulus** | https://github.com/NVIDIA/modulus |
| **PyTorch Geometric** | https://pytorch-geometric.readthedocs.io |
| **DGLâ€‘LifeSci** | https://lifesci.dgl.ai/ |
| **JAX MD** | https://github.com/google/jax-md |
| **Jraph** | https://github.com/deepmind/jraph |
| **ASE** | https://wiki.fysik.dtu.dk/ase/ |
| **pymatgen** | https://pymatgen.org/ |

---

## Conferences & Community

- **NeurIPS â€“ AI4Science workshops (2021â€‘2025)**  
- **NeurIPS 2024 â€“ Foundation Models for Science (FM4Science)**  
- **ICML 2024 â€“ Foundation Models for Science (Workshop)**  
- **Nature Machine Intelligence â€“ AI4S collection**  
- **SCIâ€‘FM @ ICLR 2025** â€“ Open science for foundation models

---

## Staying Current

1. **arXiv alerts:** `cs.LG`, `cs.AI`, `cs.CL`, `stat.ML`, `physics.comp-ph`, `q-bio.BM`, `EarthComp`  
2. **Org feeds/newsletters:** DeepMind Science; NVIDIA Earthâ€‘2; ML4Sci Digest; Matterverse  
3. **Communities:** `ai4sciencecommunity` (Slack/Discord); `ml-physics`  
4. **Podcasts:** *DeepMind: The Podcast*; *ScienceML*; *Data Skeptic* (science tracks)

---

## ğŸ“† Progress Timeline

```mermaid
timeline
    title AI4S Survey â€“ Weekly Progress
    2025-07-14 : ğŸ“ Initial reading list
    2025-07-16 : ğŸ“ Kickâ€‘off meeting
    2025-07-18 : ğŸ“ GitHub repo created
    2025-07-21 : ğŸ“š Added DeepMind whiteâ€‘paper & Nature feature
    2025-07-22 : âœï¸ Drafted survey outline & abstract
    2025-07-23 : ğŸ”„ 2nd Meeting with Center Director
    2025-07-25 : âœï¸ Incorporated agentâ€‘trend; refined reading list
    2025-07-29 : ğŸ“ Continuous updates
    2025-07-31 : ğŸ”„ 3rd Meeting ~
    2025-08-06 : ğŸ“ Last update
    2025-08-07 : ğŸ”„ 4th Meeting ~

### <summary>ğŸ“… Highâ€‘Level Milestone Plan</summary>

| Phase                     | Dates (2025)    | Deliverable            |
| ------------------------- | --------------- | ---------------------- |
| LiteratureÂ & Gapâ€‘analysis | Julâ€¯14â€¯â€“â€¯Augâ€¯14 | Annotated notes        |
| Outline Freeze            | Augâ€¯18â€¯â€“â€¯Augâ€¯25 | Locked survey outline  |
| Writing Sprint            | Augâ€¯26â€¯â€“â€¯Sepâ€¯26 | Full draft             |
| Internal Review           | Sepâ€¯29â€¯â€“â€¯Octâ€¯15 | Feedback incorporated  |
| Submission                | Octâ€¯17          | Preâ€‘print & submission |

---

## Contributing

Open an issue or pull request including:

1. **Section** (e.g., CoreÂ Methodologies â†’ PINNs)
2. **Resource type** (paper / dataset / tool / tutorial)
3. **Oneâ€‘line rationale**

## License

Creative Commons AttributionÂ 4.0 International (CCâ€‘BYâ€‘4.0)

---

**Notes on key links I verified while revising this README (for your confidence):**  
- **AI Coâ€‘Scientist (Google)** overview, agents, and examples. :contentReference[oaicite:0]{index=0}  
- **The AI Scientist** (Sakana) system description.   
- **PaperQA2** repo (literatureâ€‘first agent) and **LitQA2** benchmark. :contentReference[oaicite:2]{index=2}  
- **AgentBoard** benchmark (multiâ€‘turn agent evaluation).   
- **OpenAlex** & **ORKG** for scholarly graphs/evidence. :contentReference[oaicite:4]{index=4}  
- **SciGLM / SciInstruct**, **BioMedLM**, **BioGPT** (domain Sciâ€‘LLMs). :contentReference[oaicite:5]{index=5}  
- **WeatherNext** (DeepMind 2025) & **GNoME** (2.2M crystals). :contentReference[oaicite:6]{index=6}  
- **OCx24** dataset (Open Catalyst 2024). :contentReference[oaicite:7]{index=7}  
- **AlphaFoldÂ 3** paper (Nature 2024). :contentReference[oaicite:8]{index=8}  
- **ASIâ€‘Arch** (2025). :contentReference[oaicite:9]{index=9}  
- **Argonne/UChicago Polybot** autonomous lab. :contentReference[oaicite:10]{index=10}  
- **ChemOS / ChemOSÂ 2.0** and the **mobile robotic chemist**. :contentReference[oaicite:11]{index=11}
