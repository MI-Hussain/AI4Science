# AIâ€‘forâ€‘Science â€“ Foundation Models Focused Reading List & Survey Outline

> **Last updated:** 30â€¯Julâ€¯2025  
> Curated resources for a forthcoming **Survey** on *scientific foundation models* (SciFMs) â€“ large, generallyâ€‘preâ€‘trained AI systems that can be adapted to diverse scientific problems with minimal additional data or compute.

---

## Tableâ€¯ofâ€¯Contents
1. [Survey Outline](#survey-outline)
2. [Foundationâ€‘Model Breakthrough Timeline](#foundation-model-breakthrough-timeline)
3. [Landscape of Scientific Foundation Models](#landscape-of-scientific-foundation-models)  
   1. [Crossâ€‘disciplinary LanguageÂ &â€¯Multimodal](#31-cross-disciplinary-language--multimodal)  
   2. [Lifeâ€‘SciencesÂ & Structural Biology](#32-life-sciences--structural-biology)  
   3. [MaterialsÂ & Chemistry](#33-materials--chemistry)  
   4. [Earthâ€‘System & Climate Science](#34-earth-system--climate-science)
4. [Benchmarks & Datasets](#benchmarks--datasets)
5. [Software & Frameworks](#software--frameworks)
6. [Conferences & Community](#conferences--community)
7. [Staying Current](#staying-current)
8. [Progress Timeline](#progress-timeline)
9. [Highâ€‘Level Milestone Plan](#high-level-milestone-plan)
10. [Contributing](#contributing)
11. [License](#license)

---

## Surveyâ€¯Outline

### *Scientific Foundation Models: Catalysing the Next Wave of Discovery*

Foundation models (FMs) preâ€‘train on petabyteâ€‘scale, heterogeneous data then specialise rapidly via fineâ€‘tuning, prompting or lowâ€‘rank adaptation.  
This survey:  

* **Defines SciFMs** â€“ language, visionâ€‘language, graph and physicsâ€‘based backbones unified by transferable scientific representations.  
* **Maps impact trajectories** across hypothesis generation, simulation, instrumentation control and robotic experimentation.  
* **Dissects challenges** â€“ data bias, evaluation, safety, compute equity and responsible openâ€‘sourcing.  
* **Forecasts trends** â€“ agentic SciFMs, hybrid neuroâ€‘symbolic FMs, and quantumâ€‘accelerated training.

---

## Foundationâ€‘Model Breakthrough Timeline

| Year | Milestone | Why it matters |
|------|-----------|----------------|
| 2021 | **AlphaFoldâ€¯2** â€“ nearâ€‘atomic protein structures | Sparked the SciFM eraÂ :contentReference[oaicite:0]{index=0} |
| 2022 | **GalacticaÂ (120â€¯B)** â€“ large language model trained on 48â€¯M scientific papersÂ :contentReference[oaicite:1]{index=1} | Crossâ€‘domain textual reasoning |
| 2023 | **GraphCast** â€“ mediumâ€‘range global weather FM beating ECMWFÂ :contentReference[oaicite:2]{index=2} |
| 2023 | **GNoME** â€“ crystalâ€‘stability FM predictsâ€¯2.2â€¯M new materialsÂ :contentReference[oaicite:3]{index=3} |
| 2024 | **PrithviÂ WxC** â€“ NASAâ€‘IBM openâ€‘source climate FMÂ :contentReference[oaicite:4]{index=4} |
| 2024 | **AlphaFoldâ€¯3** â€“ complexes & interactions via diffusion/PairformerÂ :contentReference[oaicite:5]{index=5} |
| 2024 | **Aurora (1.3â€¯B)** â€“ 3â€‘D Earthâ€‘system FM; Nature paperÂ :contentReference[oaicite:6]{index=6} |
| 2025 | **WeatherNext** â€“ diffusionâ€‘based operational forecasts via DeepMindÂ :contentReference[oaicite:7]{index=7} |
| 2025 | **IntFold** â€“ controllable biomolecular FM rivaling AlphaFoldâ€¯3Â :contentReference[oaicite:8]{index=8} |

---

## Landscape of Scientific Foundationâ€¯Models

### 3.1Â Crossâ€‘disciplinary LanguageÂ &â€¯Multimodal
| Model | Scale | Modality | Highlight |
|-------|-------|----------|-----------|
| **Galactica**Â (Meta)Â :contentReference[oaicite:9]{index=9} | 120â€¯B | Text | Trained on 48â€¯M papers; scientific QA & equation handling |
| **SciGPT** (community forks) | 7â€“70â€¯B | Text | Open fineâ€‘tunes of GPTâ€‘style LLMs on arXiv & PubMed |
| **PaliGemma / MedGemma** | 3â€¯B | Visionâ€‘Language | Multiâ€‘image/multiâ€‘modal preâ€‘training; strong transfer to biomedical VQA |

### 3.2Â Lifeâ€‘SciencesÂ & Structural Biology
| Model | Modality | Key capability |
|-------|----------|----------------|
| **AlphaFoldâ€¯3**Â :contentReference[oaicite:10]{index=10} | Structure & interactions | Proteinsâ€¯+â€¯RNA/DNAâ€¯+â€¯ligands |
| **IntFold**Â :contentReference[oaicite:11]{index=11} | Controllable allâ€‘atom structure FM | Fineâ€‘grained control for drug design |
| **ProGenâ€¯2** | Protein language | Generative protein design at 25â€¯B params |

### 3.3Â MaterialsÂ & Chemistry
| Model | Modality | Key capability |
|-------|----------|----------------|
| **GNoME**Â :contentReference[oaicite:12]{index=12} | Graphâ€‘based crystal FM | Predicts stability of >2â€¯M novel crystals |
| **Open CatalystÂ (FM family)** | Graph & energy grids | Catalyst binding energies & kinetics |
| **MatSciâ€‘FM (Open MatSci Toolkit)**Â :contentReference[oaicite:13]{index=13} | Multiâ€‘task graph FM | Unified materials property prediction & generative design |

### 3.4Â Earthâ€‘System & Climate Science
| Model | Range | Distinctive feature |
|-------|-------|---------------------|
| **GraphCast**Â :contentReference[oaicite:14]{index=14} | 10â€‘day global | GNN; <60â€¯s on TPU |
| **Aurora**Â :contentReference[oaicite:15]{index=15} | Atmosphere & ocean | 3â€‘D Swin/Perceiver; subsumes airâ€‘quality & cyclone tracks |
| **WeatherNext**Â :contentReference[oaicite:16]{index=16} | Nowâ€‘cast â†’ mediumâ€‘range | Diffusion ensemble + Cloud API |
| **Prithviâ€¯WxC**Â :contentReference[oaicite:17]{index=17} | Weatherâ€‘Climate dual FM | Openâ€‘sourced via Huggingâ€¯Face; NASA reanalysis preâ€‘train |

---

## Benchmarksâ€¯&â€¯Datasets

* **Protein:** PDB, AlphaFoldÂ DB  
* **Materials:** Materialsâ€¯Project, OQMD, **MatBenchâ€‘FM** (100 small tasks for SciFMs)  
* **Catalysis:** OC20 / **OCx24** experimental extension :contentReference[oaicite:18]{index=18}  
* **Climate:** ERA5, **ClimateBenchâ€‘FM** subset for Earth FMs  
* **Textual Science QA:** ScienceBench

---

## Softwareâ€¯&â€¯Frameworks

| Purpose | Tool / Library |
|---------|----------------|
| FM preâ€‘training | **Megatronâ€‘DeepSpeed**, **JAXâ€¯/â€¯Flax** |
| Scientific graphs | **PyTorchÂ Geometric**, **DGLâ€‘LifeSci** |
| Physics FMs | **Modulus** (PINNâ†’FM pipeline), **PySizing** |
| Deployment | **ONNXâ€‘Runtimeâ€‘Inferenceâ€‘Server**, **vLLM** |

---

## Conferencesâ€¯&â€¯Community

* **SciFM25 â€“ Scientific Foundation Models & AI Agents for Science**Â :contentReference[oaicite:19]{index=19}  
* **NeurIPS & ICML Workshops:** *Foundation Models for Science* (2024â€‘25)  
* **NASAâ€¯Openâ€‘Science Summits** â€“ PrithviÂ WxC tutorials

---

## Stayingâ€¯Current

* **arXiv categories:** `cs.LG`, `physics.comp-ph`, `q-bio.BM`, `stat.ML` with *foundationâ€‘model* keyword  
* **Newsletters:** *DeepMind Science*, *SciFM Digest*  
* **Slack/Discord:** `foundation-models-science`, `ai4sciencecommunity`

---

## ðŸ“†Â Progress Timeline

```mermaid
timeline
    title SciFM Survey â€“ Weekly Progress
    2025-07-14 : ðŸ“ Initial FM reading list
    2025-07-23 : ðŸ”„ Scope narrowed to foundation models
    2025-07-30 : ðŸ“š Added Aurora, IntFold, WeatherNext

---

## Highâ€‘Level Milestone Plan
Phase	Dates (2025)	Deliverable
Gapâ€‘analysis	Julâ€¯30â€¯â€“â€¯Augâ€¯10	Annotated FM taxonomy
Outline Freeze	Augâ€¯18â€¯â€“â€¯Augâ€¯25	Locked FMâ€‘centric outline
Writing Sprint	Augâ€¯26â€¯â€“â€¯Sepâ€¯26	Full draft
Internal Review	Sepâ€¯29â€¯â€“â€¯Octâ€¯15	Consolidated feedback
Submission	Octâ€¯17	Preâ€‘print & journal submission

Contributing
Please open an issue or PR with:

Section (e.g., Earthâ€‘SystemÂ â†’ Aurora)

Resource type (paper / dataset / tool)

Oneâ€‘line rationale

License
CreativeÂ Commons AttributionÂ 4.0 International (CCâ€‘BYâ€‘4.0)

markdown
Copy

---

### What changed?

* **Scope trimmed** to foundation models; nonâ€‘FM methodology sections (PINNs, GNNs, etc.) were removed.  
* **Timeline** now highlights eight core SciFM milestones with citations.  
* **Reading list** reorganised by domainâ€‘specific SciFMs.  
* Added **Aurora, WeatherNext, IntFold, PrithviÂ WxC** and **Galactica** entries.  
* Updated **frameworks** table to emphasise FM training/deployment stacks.

Feel free to adjust naming, add your own models, or reinstate earlier sections if still relevant.
::contentReference[oaicite:20]{index=20}
